{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b0594c1-8cdd-4ec8-a561-bb656a77305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import optim\n",
    "from collections import OrderedDict\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e61c9293-4336-4900-93e9-50707d07600f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                               transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "trainset = datasets.FashionMNIST('F_MNIST_data', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = datasets.FashionMNIST('F_MNIST_data', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5a814a5-e4ac-4a56-8175-ff541c83984c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d0e7898be0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d0e7898518>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "helper.imshow(images[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f346605-2040-498a-8fc8-0b58403577dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 200)\n",
      "(200, 100)\n",
      "(100, 50)\n",
      "(50, 50)\n"
     ]
    }
   ],
   "source": [
    "hidden_layer = [500, 200, 100, 50, 50]\n",
    "hidden_layer = zip(hidden_layer[:-1], hidden_layer[1:])\n",
    "for i in hidden_layer:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba59f8a-8b75-4a10-b41f-2cacc7d4be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, drop_p=0.5):\n",
    "        super().__init__()\n",
    "        self.network_layer = nn.ModuleList([nn.Linear(input_size, hidden_size[0])])\n",
    "        layer_sizes = zip(hidden_size[:-1], hidden_size[1:])\n",
    "        self.network_layer.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        self.output = nn.Linear(hidden_size[-1], output_size)\n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for linear_layer in self.network_layer:\n",
    "            x = F.relu(linear_layer(x))\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "        x = self.output(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c67867-e3cd-42c0-b18d-5e4d34f5e3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size = [512, 256, 128]\n",
    "output_size = 10\n",
    "drop_p = 0.5\n",
    "model = Network(input_size, hidden_size, output_size, drop_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "355b829b-1abb-40a8-84b0-b765ccdea700",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8822a7b-2844-4f1d-94f8-7a234e570af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, testloader, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    for images, labels in testloader:\n",
    "        images.resize_(images.shape[0], 784)\n",
    "        output = model.forward(images)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07dbf9f3-13c5-45d4-8e7d-96f99c76c520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:1/1 train loss:0.0264,  test loss: 0.4831,  test accuracy:0.8238\n",
      "epochs:1/1 train loss:0.0093,  test loss: 0.4750,  test accuracy:0.8237\n",
      "epochs:1/1 train loss:0.0169,  test loss: 0.4709,  test accuracy:0.8220\n",
      "epochs:1/1 train loss:0.0098,  test loss: 0.4792,  test accuracy:0.8207\n",
      "epochs:1/1 train loss:0.0152,  test loss: 0.4767,  test accuracy:0.8252\n",
      "epochs:1/1 train loss:0.0068,  test loss: 0.4666,  test accuracy:0.8354\n",
      "epochs:1/1 train loss:0.0142,  test loss: 0.4689,  test accuracy:0.8267\n",
      "epochs:1/1 train loss:0.0186,  test loss: 0.4674,  test accuracy:0.8323\n",
      "epochs:1/1 train loss:0.0167,  test loss: 0.4629,  test accuracy:0.8318\n",
      "epochs:1/1 train loss:0.0101,  test loss: 0.4630,  test accuracy:0.8328\n",
      "epochs:1/1 train loss:0.0101,  test loss: 0.4632,  test accuracy:0.8282\n",
      "epochs:1/1 train loss:0.0109,  test loss: 0.4750,  test accuracy:0.8292\n",
      "epochs:1/1 train loss:0.0126,  test loss: 0.4675,  test accuracy:0.8333\n",
      "epochs:1/1 train loss:0.0125,  test loss: 0.4642,  test accuracy:0.8349\n",
      "epochs:1/1 train loss:0.0124,  test loss: 0.4481,  test accuracy:0.8308\n",
      "epochs:1/1 train loss:0.0107,  test loss: 0.4492,  test accuracy:0.8448\n",
      "epochs:1/1 train loss:0.0122,  test loss: 0.4455,  test accuracy:0.8383\n",
      "epochs:1/1 train loss:0.0107,  test loss: 0.4496,  test accuracy:0.8387\n",
      "epochs:1/1 train loss:0.0093,  test loss: 0.4436,  test accuracy:0.8365\n",
      "epochs:1/1 train loss:0.0114,  test loss: 0.4481,  test accuracy:0.8343\n",
      "epochs:1/1 train loss:0.0157,  test loss: 0.4481,  test accuracy:0.8310\n",
      "epochs:1/1 train loss:0.0081,  test loss: 0.4415,  test accuracy:0.8367\n",
      "epochs:1/1 train loss:0.0131,  test loss: 0.4493,  test accuracy:0.8366\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "print_every = 40\n",
    "steps = 0\n",
    "for e in range(epochs):\n",
    "    runnings_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        steps += 1\n",
    "        images.resize_(images.size()[0], input_size)\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        runnings_loss = loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_loss, accuracy = validation(model, testloader, criterion)\n",
    "            print(f'epochs:{e+1}/{epochs}',\n",
    "                  'train loss:{:.4f}, '.format(runnings_loss/print_every), \n",
    "                 'test loss: {:.4f}, '.format(test_loss/len(testloader)), \n",
    "                 'test accuracy:{:.4f}'.format(accuracy/len(testloader)))\n",
    "            runnings_loss = 0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22ca323b-4b30-4040-ab41-06ed8d08b29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (network_layer): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "odict_keys(['network_layer.0.weight', 'network_layer.0.bias', 'network_layer.1.weight', 'network_layer.1.bias', 'network_layer.2.weight', 'network_layer.2.bias', 'output.weight', 'output.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3604da79-0d05-4722-89b5-a81fee994c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {'input_size':784, \n",
    "             'hidden_size':[each.out_features for each in model.network_layer], \n",
    "             'output_size':10, \n",
    "             'state_dict':model.state_dict()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9b66d1a-6a78-48a4-97dc-1004539fb9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(checkpoint, \"cp.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06bb4493-5758-4d18-b04f-78721d7e0bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = Network(checkpoint['input_size'], \n",
    "                   checkpoint['hidden_size'], \n",
    "                   checkpoint['output_size'])\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab6c01a3-2fad-4e36-9f21-5fcad4d52262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (network_layer): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "new_model = load_model(\"cp.pth\")\n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0ab6a-9a66-4d03-be4d-add0a59eb76f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
