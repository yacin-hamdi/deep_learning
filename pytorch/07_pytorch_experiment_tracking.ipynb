{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 07 PyTorch Experiment Tracking"
      ],
      "metadata": {
        "id": "NOi67t-br--N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8OcNlXEu4FZ",
        "outputId": "6723a9c5-4fea-4f73-f845-06fda3d43aee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n",
            "0.18.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkxWWcyhvfLL",
        "outputId": "6485f487-f40c-492a-b635-6cacc9f071ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4056, done.\u001b[K\n",
            "remote: Total 4056 (delta 0), reused 0 (delta 0), pack-reused 4056\u001b[K\n",
            "Receiving objects: 100% (4056/4056), 646.90 MiB | 29.85 MiB/s, done.\n",
            "Resolving deltas: 100% (2371/2371), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GVDKLga7wjDW",
        "outputId": "25d62439-4b6c-4f3f-9f98-9feec57d2fe2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds\n",
        "def set_seeds(seed: int=42):\n",
        "    \"\"\"Sets random sets for torch operations.\n",
        "\n",
        "    Args:\n",
        "        seed (int, optional): Random seed to set. Defaults to 42.\n",
        "    \"\"\"\n",
        "    # Set the seed for general torch operations\n",
        "    torch.manual_seed(seed)\n",
        "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
        "    torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "awH7wMB2wxZx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seeds()"
      ],
      "metadata": {
        "id": "a5miV7oow4YJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get data"
      ],
      "metadata": {
        "id": "zePG6L7aw6Nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "def download_data(source: str,\n",
        "                  destination: str,\n",
        "                  remove_source: bool=True) -> Path:\n",
        "  \"\"\" Downloads a zipped dataset from source and unzips to destination...\"\"\"\n",
        "  data_path = Path(\"data/\")\n",
        "  image_path = data_path / destination\n",
        "  if image_path.is_dir():\n",
        "    print(f\"[INFO] {image_path} directory already exists, skipping download.\")\n",
        "  else:\n",
        "    print(f\"[INFO] Did not find {image_path} directory, downloading...\")\n",
        "    image_path.mkdir(parents=True, exist_ok = True)\n",
        "    target_file = Path(source).name\n",
        "    with open(data_path / target_file, \"wb\") as f:\n",
        "      request = requests.get(source)\n",
        "      print(f\"[INFO] Downloading {target_file} from {source}...\")\n",
        "      f.write(request.content)\n",
        "\n",
        "    with zipfile.ZipFile(data_path / target_file, \"r\") as zip_ref:\n",
        "      print(f\"[INFO] Unzipping {target_file} data...\")\n",
        "      zip_ref.extractall(image_path)\n",
        "\n",
        "    if remove_source:\n",
        "      os.remove(data_path / target_file)\n",
        "\n",
        "  return image_path"
      ],
      "metadata": {
        "id": "bx4gtyPCxexl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                           destination=\"pizza_steak_sushi\")\n",
        "image_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xEAHYzrzdxP",
        "outputId": "d5eb0674-51ec-4740-ab6e-d0fc64f20adc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Did not find data/pizza_steak_sushi directory, downloading...\n",
            "[INFO] Downloading pizza_steak_sushi.zip from https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip...\n",
            "[INFO] Unzipping pizza_steak_sushi.zip data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('data/pizza_steak_sushi')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create Datasets and DataLoaders"
      ],
      "metadata": {
        "id": "5o_FtW6g28bJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Create DataLoaders with manual transforms"
      ],
      "metadata": {
        "id": "JyVORym73AZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from going_modular.going_modular import data_setup\n",
        "\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "manual_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=manual_transform,\n",
        "                                                                               batch_size=BATCH_SIZE,\n",
        "                                                                               num_workers=NUM_WORKERS)\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgI-5umIzqKt",
        "outputId": "98e2a166-ceb2-4554-dca2-59d66d53ea35"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7c334ab2dbd0>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7c334ab2d060>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Create DataLoaders with auto transforms"
      ],
      "metadata": {
        "id": "qHVE7ym32czk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "auto_transform = weights.transforms()\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=auto_transform,\n",
        "                                                                               batch_size=BATCH_SIZE,\n",
        "                                                                               num_workers=NUM_WORKERS)\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joCT6ZJ44ddU",
        "outputId": "fc645b8b-fd75-4848-f670-d1a8484ede1f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7c334bb36e90>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7c334bb37f10>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Getting a pretrained model, freeze the base layers and change the classifier head"
      ],
      "metadata": {
        "id": "aD-kpnDr9Ru_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "model_0 = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
        "\n",
        "summary(model=model_0,\n",
        "        input_size=(1, 3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGA30Nl-5PEz",
        "outputId": "d8842149-f468-4385-d0dc-062a564af0c0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=========================================================================================================\n",
              "Layer (type:depth-idx)                                  Output Shape              Param #\n",
              "=========================================================================================================\n",
              "EfficientNet                                            [1, 1000]                 --\n",
              "├─Sequential: 1-1                                       [1, 1280, 7, 7]           --\n",
              "│    └─Conv2dNormActivation: 2-1                        [1, 32, 112, 112]         --\n",
              "│    │    └─Conv2d: 3-1                                 [1, 32, 112, 112]         864\n",
              "│    │    └─BatchNorm2d: 3-2                            [1, 32, 112, 112]         64\n",
              "│    │    └─SiLU: 3-3                                   [1, 32, 112, 112]         --\n",
              "│    └─Sequential: 2-2                                  [1, 16, 112, 112]         --\n",
              "│    │    └─MBConv: 3-4                                 [1, 16, 112, 112]         1,448\n",
              "│    └─Sequential: 2-3                                  [1, 24, 56, 56]           --\n",
              "│    │    └─MBConv: 3-5                                 [1, 24, 56, 56]           6,004\n",
              "│    │    └─MBConv: 3-6                                 [1, 24, 56, 56]           10,710\n",
              "│    └─Sequential: 2-4                                  [1, 40, 28, 28]           --\n",
              "│    │    └─MBConv: 3-7                                 [1, 40, 28, 28]           15,350\n",
              "│    │    └─MBConv: 3-8                                 [1, 40, 28, 28]           31,290\n",
              "│    └─Sequential: 2-5                                  [1, 80, 14, 14]           --\n",
              "│    │    └─MBConv: 3-9                                 [1, 80, 14, 14]           37,130\n",
              "│    │    └─MBConv: 3-10                                [1, 80, 14, 14]           102,900\n",
              "│    │    └─MBConv: 3-11                                [1, 80, 14, 14]           102,900\n",
              "│    └─Sequential: 2-6                                  [1, 112, 14, 14]          --\n",
              "│    │    └─MBConv: 3-12                                [1, 112, 14, 14]          126,004\n",
              "│    │    └─MBConv: 3-13                                [1, 112, 14, 14]          208,572\n",
              "│    │    └─MBConv: 3-14                                [1, 112, 14, 14]          208,572\n",
              "│    └─Sequential: 2-7                                  [1, 192, 7, 7]            --\n",
              "│    │    └─MBConv: 3-15                                [1, 192, 7, 7]            262,492\n",
              "│    │    └─MBConv: 3-16                                [1, 192, 7, 7]            587,952\n",
              "│    │    └─MBConv: 3-17                                [1, 192, 7, 7]            587,952\n",
              "│    │    └─MBConv: 3-18                                [1, 192, 7, 7]            587,952\n",
              "│    └─Sequential: 2-8                                  [1, 320, 7, 7]            --\n",
              "│    │    └─MBConv: 3-19                                [1, 320, 7, 7]            717,232\n",
              "│    └─Conv2dNormActivation: 2-9                        [1, 1280, 7, 7]           --\n",
              "│    │    └─Conv2d: 3-20                                [1, 1280, 7, 7]           409,600\n",
              "│    │    └─BatchNorm2d: 3-21                           [1, 1280, 7, 7]           2,560\n",
              "│    │    └─SiLU: 3-22                                  [1, 1280, 7, 7]           --\n",
              "├─AdaptiveAvgPool2d: 1-2                                [1, 1280, 1, 1]           --\n",
              "├─Sequential: 1-3                                       [1, 1000]                 --\n",
              "│    └─Dropout: 2-10                                    [1, 1280]                 --\n",
              "│    └─Linear: 2-11                                     [1, 1000]                 1,281,000\n",
              "=========================================================================================================\n",
              "Total params: 5,288,548\n",
              "Trainable params: 5,288,548\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 385.87\n",
              "=========================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 107.89\n",
              "Params size (MB): 21.15\n",
              "Estimated Total Size (MB): 129.64\n",
              "========================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model_0.features.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "set_seeds()\n",
        "\n",
        "model_0.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.3, inplace=True),\n",
        "    nn.Linear(in_features=1280, out_features=len(class_names))\n",
        "\n",
        ").to(device)\n",
        "\n",
        "summary(model=model_0,\n",
        "        input_size=(1, 3, 224, 224),\n",
        "        verbose=0,\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        row_settings=['var_names'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcALpEd38GLS",
        "outputId": "d4823ae0-94c4-4169-930a-01b31ea8498c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "================================================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape               Output Shape              Param #                   Trainable\n",
              "================================================================================================================================================================\n",
              "EfficientNet (EfficientNet)                                  [1, 3, 224, 224]          [1, 3]                    --                        Partial\n",
              "├─Sequential (features)                                      [1, 3, 224, 224]          [1, 1280, 7, 7]           --                        False\n",
              "│    └─Conv2dNormActivation (0)                              [1, 3, 224, 224]          [1, 32, 112, 112]         --                        False\n",
              "│    │    └─Conv2d (0)                                       [1, 3, 224, 224]          [1, 32, 112, 112]         (864)                     False\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 32, 112, 112]         [1, 32, 112, 112]         (64)                      False\n",
              "│    │    └─SiLU (2)                                         [1, 32, 112, 112]         [1, 32, 112, 112]         --                        --\n",
              "│    └─Sequential (1)                                        [1, 32, 112, 112]         [1, 16, 112, 112]         --                        False\n",
              "│    │    └─MBConv (0)                                       [1, 32, 112, 112]         [1, 16, 112, 112]         (1,448)                   False\n",
              "│    └─Sequential (2)                                        [1, 16, 112, 112]         [1, 24, 56, 56]           --                        False\n",
              "│    │    └─MBConv (0)                                       [1, 16, 112, 112]         [1, 24, 56, 56]           (6,004)                   False\n",
              "│    │    └─MBConv (1)                                       [1, 24, 56, 56]           [1, 24, 56, 56]           (10,710)                  False\n",
              "│    └─Sequential (3)                                        [1, 24, 56, 56]           [1, 40, 28, 28]           --                        False\n",
              "│    │    └─MBConv (0)                                       [1, 24, 56, 56]           [1, 40, 28, 28]           (15,350)                  False\n",
              "│    │    └─MBConv (1)                                       [1, 40, 28, 28]           [1, 40, 28, 28]           (31,290)                  False\n",
              "│    └─Sequential (4)                                        [1, 40, 28, 28]           [1, 80, 14, 14]           --                        False\n",
              "│    │    └─MBConv (0)                                       [1, 40, 28, 28]           [1, 80, 14, 14]           (37,130)                  False\n",
              "│    │    └─MBConv (1)                                       [1, 80, 14, 14]           [1, 80, 14, 14]           (102,900)                 False\n",
              "│    │    └─MBConv (2)                                       [1, 80, 14, 14]           [1, 80, 14, 14]           (102,900)                 False\n",
              "│    └─Sequential (5)                                        [1, 80, 14, 14]           [1, 112, 14, 14]          --                        False\n",
              "│    │    └─MBConv (0)                                       [1, 80, 14, 14]           [1, 112, 14, 14]          (126,004)                 False\n",
              "│    │    └─MBConv (1)                                       [1, 112, 14, 14]          [1, 112, 14, 14]          (208,572)                 False\n",
              "│    │    └─MBConv (2)                                       [1, 112, 14, 14]          [1, 112, 14, 14]          (208,572)                 False\n",
              "│    └─Sequential (6)                                        [1, 112, 14, 14]          [1, 192, 7, 7]            --                        False\n",
              "│    │    └─MBConv (0)                                       [1, 112, 14, 14]          [1, 192, 7, 7]            (262,492)                 False\n",
              "│    │    └─MBConv (1)                                       [1, 192, 7, 7]            [1, 192, 7, 7]            (587,952)                 False\n",
              "│    │    └─MBConv (2)                                       [1, 192, 7, 7]            [1, 192, 7, 7]            (587,952)                 False\n",
              "│    │    └─MBConv (3)                                       [1, 192, 7, 7]            [1, 192, 7, 7]            (587,952)                 False\n",
              "│    └─Sequential (7)                                        [1, 192, 7, 7]            [1, 320, 7, 7]            --                        False\n",
              "│    │    └─MBConv (0)                                       [1, 192, 7, 7]            [1, 320, 7, 7]            (717,232)                 False\n",
              "│    └─Conv2dNormActivation (8)                              [1, 320, 7, 7]            [1, 1280, 7, 7]           --                        False\n",
              "│    │    └─Conv2d (0)                                       [1, 320, 7, 7]            [1, 1280, 7, 7]           (409,600)                 False\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 1280, 7, 7]           [1, 1280, 7, 7]           (2,560)                   False\n",
              "│    │    └─SiLU (2)                                         [1, 1280, 7, 7]           [1, 1280, 7, 7]           --                        --\n",
              "├─AdaptiveAvgPool2d (avgpool)                                [1, 1280, 7, 7]           [1, 1280, 1, 1]           --                        --\n",
              "├─Sequential (classifier)                                    [1, 1280]                 [1, 3]                    --                        True\n",
              "│    └─Dropout (0)                                           [1, 1280]                 [1, 1280]                 --                        --\n",
              "│    └─Linear (1)                                            [1, 1280]                 [1, 3]                    3,843                     True\n",
              "================================================================================================================================================================\n",
              "Total params: 4,011,391\n",
              "Trainable params: 3,843\n",
              "Non-trainable params: 4,007,548\n",
              "Total mult-adds (M): 384.59\n",
              "================================================================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 107.88\n",
              "Params size (MB): 16.05\n",
              "Estimated Total Size (MB): 124.53\n",
              "================================================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. train a single model and track results"
      ],
      "metadata": {
        "id": "ZDIAS5jx8pny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_0.parameters(),\n",
        "                              lr=0.001)"
      ],
      "metadata": {
        "id": "8Zh8yLrrAwex"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup a SummaryWriter\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()\n",
        "writer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92DhtlnOA-Wx",
        "outputId": "15cae748-dcae-4bb9-9a07-8a55926a9b13"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.tensorboard.writer.SummaryWriter at 0x7c32eecff190>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List, Tuple\n",
        "from going_modular.going_modular.engine import train_step, test_step\n"
      ],
      "metadata": {
        "id": "7PDZPviQBG-H"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device) -> Dict[str, List]:\n",
        "\n",
        "    # Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    # Make sure model on target device\n",
        "    model.to(device)\n",
        "\n",
        "    # Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=loss_fn,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device)\n",
        "\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "        ### New: Experiment tracking ###\n",
        "        writer.add_scalars(main_tag=\"Loss\",\n",
        "                           tag_scalar_dict={\"train_loss\":train_loss,\n",
        "                                            \"test_loss\":test_loss},\n",
        "                           global_step=epoch)\n",
        "\n",
        "        writer.add_scalars(main_tag=\"Accuracy\",\n",
        "                           tag_scalar_dict={\"train_acc\": train_acc,\n",
        "                                            \"test_acc\": test_acc},\n",
        "                           global_step=epoch)\n",
        "\n",
        "        writer.add_graph(model=model,\n",
        "                         input_to_model=torch.randdn(32, 3, 224, 224).to(device))\n",
        "    writer.close()\n",
        "\n",
        "    # Return the filled results at the end of the epochs\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "T5qUuSi-CaJs"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9_EgHuEHDwBq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}