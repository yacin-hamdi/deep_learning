{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pytorch Quick Intro","metadata":{}},{"cell_type":"code","source":"import torch\nprint(torch.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:12:14.140569Z","iopub.execute_input":"2024-06-12T10:12:14.141204Z","iopub.status.idle":"2024-06-12T10:12:18.639469Z","shell.execute_reply.started":"2024-06-12T10:12:14.141172Z","shell.execute_reply":"2024-06-12T10:12:18.638102Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"2.1.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Quick code examples","metadata":{}},{"cell_type":"markdown","source":"## Before Pytorch 2.0","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\n\nmodel = torchvision.models.resnet50()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:12:18.645940Z","iopub.execute_input":"2024-06-12T10:12:18.649845Z","iopub.status.idle":"2024-06-12T10:12:20.975307Z","shell.execute_reply.started":"2024-06-12T10:12:18.649777Z","shell.execute_reply":"2024-06-12T10:12:20.974440Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## After Pytorch 2.0","metadata":{}},{"cell_type":"code","source":"import torch \nimport torchvision\n\nmodel = torchvision.models.resnet50()\ncompiled_model = torch.compile(model)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T09:57:31.335777Z","iopub.execute_input":"2024-06-12T09:57:31.337003Z","iopub.status.idle":"2024-06-12T09:57:32.365156Z","shell.execute_reply.started":"2024-06-12T09:57:31.336962Z","shell.execute_reply":"2024-06-12T09:57:32.363825Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## 1. Get GPU info","metadata":{}},{"cell_type":"code","source":"# Make sure we're using a NVIDIA GPU\nif torch.cuda.is_available():\n  gpu_info = !nvidia-smi\n  gpu_info = '\\n'.join(gpu_info)\n  if gpu_info.find(\"failed\") >= 0:\n    print(\"Not connected to a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\")\n\n  # Get GPU name\n  gpu_name = !nvidia-smi --query-gpu=gpu_name --format=csv\n  gpu_name = gpu_name[1]\n  GPU_NAME = gpu_name.replace(\" \", \"_\") # remove underscores for easier saving\n  print(f'GPU name: {GPU_NAME}')\n\n  # Get GPU capability score\n  GPU_SCORE = torch.cuda.get_device_capability()\n  print(f\"GPU capability score: {GPU_SCORE}\")\n  if GPU_SCORE >= (8, 0):\n    print(f\"GPU score higher than or equal to (8, 0), PyTorch 2.x speedup features available.\")\n  else:\n    print(f\"GPU score lower than (8, 0), PyTorch 2.x speedup features will be limited (PyTorch 2.x speedups happen most on newer GPUs).\")\n  \n  # Print GPU info\n  print(f\"GPU information:\\n{gpu_info}\")\n\nelse:\n  print(\"PyTorch couldn't find a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:12:27.749421Z","iopub.execute_input":"2024-06-12T10:12:27.749939Z","iopub.status.idle":"2024-06-12T10:12:27.980620Z","shell.execute_reply.started":"2024-06-12T10:12:27.749891Z","shell.execute_reply":"2024-06-12T10:12:27.979610Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"GPU name: Tesla_T4\nGPU capability score: (7, 5)\nGPU score lower than (8, 0), PyTorch 2.x speedup features will be limited (PyTorch 2.x speedups happen most on newer GPUs).\nGPU information:\nWed Jun 12 10:12:27 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n| N/A   33C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n| N/A   42C    P8              10W /  70W |      3MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 1.1 Globally set device","metadata":{}},{"cell_type":"code","source":"import torch \n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n\n# Set the device with context manager(PyTorch 2.x+)\nwith torch.device(device):\n    layer = torch.nn.Linear(20, 30)\n    print(f\"layer weights are on device: {layer.weight.device}\")\n    print(f\"layer creating data on device: {layer(torch.randn(128, 20)).device}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:19:59.221698Z","iopub.execute_input":"2024-06-12T10:19:59.222055Z","iopub.status.idle":"2024-06-12T10:19:59.229172Z","shell.execute_reply.started":"2024-06-12T10:19:59.222026Z","shell.execute_reply":"2024-06-12T10:19:59.228169Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"layer weights are on device: cuda:0\nlayer creating data on device: cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch \n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Set the device globally (Pytorch 2.x+)\ntorch.set_default_device(device)\n\nlayer = torch.nn.Linear(20, 30)\nprint(f\"layer weights are on device: {layer.weight.device}\")\nprint(f\"layer creating data on device: {layer(torch.randn(128, 20)).device}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:21:42.075637Z","iopub.execute_input":"2024-06-12T10:21:42.076222Z","iopub.status.idle":"2024-06-12T10:21:42.083488Z","shell.execute_reply.started":"2024-06-12T10:21:42.076191Z","shell.execute_reply":"2024-06-12T10:21:42.082526Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"layer weights are on device: cuda:0\nlayer creating data on device: cuda:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2. Setting up the experiments","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"TorchVision version: {torchvision.__version__}\")\n\n# Set the target device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:32:01.712507Z","iopub.execute_input":"2024-06-12T10:32:01.712883Z","iopub.status.idle":"2024-06-12T10:32:01.718622Z","shell.execute_reply.started":"2024-06-12T10:32:01.712852Z","shell.execute_reply":"2024-06-12T10:32:01.717741Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"PyTorch version: 2.1.2\nTorchVision version: 0.16.2\nUsing device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.set_default_device(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:34:00.875960Z","iopub.execute_input":"2024-06-12T10:34:00.876541Z","iopub.status.idle":"2024-06-12T10:34:00.881047Z","shell.execute_reply.started":"2024-06-12T10:34:00.876508Z","shell.execute_reply":"2024-06-12T10:34:00.879958Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### 2.1 Create model and transforms","metadata":{}},{"cell_type":"code","source":"\ndef create_resnet50(num_classes:int=10):\n    weights = torchvision.models.ResNet50_Weights.DEFAULT\n    transforms = weights.transforms()\n    model = torchvision.models.resnet50(weights=weights)\n    model.fc = torch.nn.Linear(in_features=2048,\n                         out_features=num_classes)\n\n    \n    return model, transforms\n    \nmodel, transforms = create_resnet50()\ntransforms","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:04:23.237396Z","iopub.execute_input":"2024-06-12T11:04:23.237934Z","iopub.status.idle":"2024-06-12T11:04:23.400611Z","shell.execute_reply.started":"2024-06-12T11:04:23.237904Z","shell.execute_reply":"2024-06-12T11:04:23.399596Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"ImageClassification(\n    crop_size=[224]\n    resize_size=[232]\n    mean=[0.485, 0.456, 0.406]\n    std=[0.229, 0.224, 0.225]\n    interpolation=InterpolationMode.BILINEAR\n)"},"metadata":{}}]},{"cell_type":"code","source":"total_params = sum(\nparam.numel() for param in model.parameters()\n)\ntotal_params","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:04:23.876897Z","iopub.execute_input":"2024-06-12T11:04:23.877241Z","iopub.status.idle":"2024-06-12T11:04:23.884395Z","shell.execute_reply.started":"2024-06-12T11:04:23.877214Z","shell.execute_reply":"2024-06-12T11:04:23.883505Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"23528522"},"metadata":{}}]},{"cell_type":"markdown","source":"### 2.2 Speedups are most noticeable when a large portion of GPU is being used","metadata":{}},{"cell_type":"markdown","source":"### 2.3 Chekcing the memory limits of our GPU","metadata":{}},{"cell_type":"code","source":"total_free_gpu_memory, total_gpu_memory = torch.cuda.mem_get_info()\nround(total_free_gpu_memory*1e-9, 3), round(total_gpu_memory*1e-9, 3)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:00:13.190023Z","iopub.execute_input":"2024-06-12T11:00:13.190897Z","iopub.status.idle":"2024-06-12T11:00:13.198500Z","shell.execute_reply.started":"2024-06-12T11:00:13.190854Z","shell.execute_reply":"2024-06-12T11:00:13.197487Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(15.25, 15.836)"},"metadata":{}}]},{"cell_type":"code","source":"# Set batch size depending on amount of GPU memory\ntotal_free_gpu_memory_gb = round(total_free_gpu_memory * 1e-9, 3)\nif total_free_gpu_memory_gb >= 15:\n  BATCH_SIZE = 128 # Note: you could experiment with higher values here if you like.\n  IMAGE_SIZE = 224\n  print(f\"GPU memory available is {total_free_gpu_memory_gb} GB, using batch size of {BATCH_SIZE} and image size {IMAGE_SIZE}\")\nelse:\n  BATCH_SIZE = 32\n  IMAGE_SIZE = 128\n  print(f\"GPU memory available is {total_free_gpu_memory_gb} GB, using batch size of {BATCH_SIZE} and image size {IMAGE_SIZE}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:01:52.561762Z","iopub.execute_input":"2024-06-12T11:01:52.562690Z","iopub.status.idle":"2024-06-12T11:01:52.568271Z","shell.execute_reply.started":"2024-06-12T11:01:52.562656Z","shell.execute_reply":"2024-06-12T11:01:52.567266Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"GPU memory available is 15.25 GB, using batch size of 128 and image size 224\n","output_type":"stream"}]},{"cell_type":"code","source":"transforms.crop_size = IMAGE_SIZE\ntransforms.resize_size = IMAGE_SIZE\ntransforms","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:04:33.374320Z","iopub.execute_input":"2024-06-12T11:04:33.374676Z","iopub.status.idle":"2024-06-12T11:04:33.380731Z","shell.execute_reply.started":"2024-06-12T11:04:33.374646Z","shell.execute_reply":"2024-06-12T11:04:33.379879Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"ImageClassification(\n    crop_size=224\n    resize_size=224\n    mean=[0.485, 0.456, 0.406]\n    std=[0.229, 0.224, 0.225]\n    interpolation=InterpolationMode.BILINEAR\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"### 2.4 More potential speeddups with TF32","metadata":{}},{"cell_type":"code","source":"if GPU_SCORE >= (8, 0):\n    print(f\"[INFO] Using GPU with score: {GPU_SCORE}, enabling TensorFloat32\")\n    torch.backends.cuda.matmul.allow_tf32 = True\nelse:\n    print(f\"[INFO] Using GPU with score: {GPU_SCORE}, TensorFloat32 not available\")\n    torch.backends.cuda.matmul.allow_tf32 = False","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:16:41.056981Z","iopub.execute_input":"2024-06-12T11:16:41.057304Z","iopub.status.idle":"2024-06-12T11:16:41.063289Z","shell.execute_reply.started":"2024-06-12T11:16:41.057280Z","shell.execute_reply":"2024-06-12T11:16:41.062227Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"[INFO] Using GPU with score: (7, 5), TensorFloat32 not available\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 2.5 Preparing dataset","metadata":{}},{"cell_type":"code","source":"train_dataset = torchvision.datasets.CIFAR10(root=\".\",\n                                             train=True,\n                                             transform=transforms,\n                                             download=True)\n\ntest_dataset = torchvision.datasets.CIFAR10(root=\".\",\n                                            train=False,\n                                            transform=transforms,\n                                            download=True)\n\nclass_names = train_dataset.classes\nlen(train_dataset), len(test_dataset), class_names","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:26:17.599043Z","iopub.execute_input":"2024-06-12T11:26:17.599790Z","iopub.status.idle":"2024-06-12T11:26:19.222622Z","shell.execute_reply.started":"2024-06-12T11:26:17.599758Z","shell.execute_reply":"2024-06-12T11:26:19.221658Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"(50000,\n 10000,\n ['airplane',\n  'automobile',\n  'bird',\n  'cat',\n  'deer',\n  'dog',\n  'frog',\n  'horse',\n  'ship',\n  'truck'])"},"metadata":{}}]},{"cell_type":"code","source":"import os\n\ntrain_dataloader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                               shuffle=True,\n                                               batch_size=BATCH_SIZE,\n                                               num_workers=os.cpu_count())\n\ntest_dataloader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                             shuffle=True,\n                                             batch_size=BATCH_SIZE,\n                                              num_workers=os.cpu_count())\n\nlen(train_dataloader), len(test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:49:08.771869Z","iopub.execute_input":"2024-06-12T11:49:08.772514Z","iopub.status.idle":"2024-06-12T11:49:08.780230Z","shell.execute_reply.started":"2024-06-12T11:49:08.772481Z","shell.execute_reply":"2024-06-12T11:49:08.779284Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"(391, 79)"},"metadata":{}}]},{"cell_type":"markdown","source":"### 2.7 Creating training and test loops","metadata":{"execution":{"iopub.status.busy":"2024-06-12T11:49:25.641853Z","iopub.execute_input":"2024-06-12T11:49:25.642217Z","iopub.status.idle":"2024-06-12T11:49:25.648195Z","shell.execute_reply.started":"2024-06-12T11:49:25.642188Z","shell.execute_reply":"2024-06-12T11:49:25.647225Z"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}