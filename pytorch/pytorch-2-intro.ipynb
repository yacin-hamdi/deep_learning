{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pytorch Quick Intro","metadata":{}},{"cell_type":"code","source":"import torch\nprint(torch.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:12:14.140569Z","iopub.execute_input":"2024-06-12T10:12:14.141204Z","iopub.status.idle":"2024-06-12T10:12:18.639469Z","shell.execute_reply.started":"2024-06-12T10:12:14.141172Z","shell.execute_reply":"2024-06-12T10:12:18.638102Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"2.1.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Quick code examples","metadata":{}},{"cell_type":"markdown","source":"## Before Pytorch 2.0","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\n\nmodel = torchvision.models.resnet50()","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:12:18.645940Z","iopub.execute_input":"2024-06-12T10:12:18.649845Z","iopub.status.idle":"2024-06-12T10:12:20.975307Z","shell.execute_reply.started":"2024-06-12T10:12:18.649777Z","shell.execute_reply":"2024-06-12T10:12:20.974440Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## After Pytorch 2.0","metadata":{}},{"cell_type":"code","source":"import torch \nimport torchvision\n\nmodel = torchvision.models.resnet50()\ncompiled_model = torch.compile(model)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T09:57:31.335777Z","iopub.execute_input":"2024-06-12T09:57:31.337003Z","iopub.status.idle":"2024-06-12T09:57:32.365156Z","shell.execute_reply.started":"2024-06-12T09:57:31.336962Z","shell.execute_reply":"2024-06-12T09:57:32.363825Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## 1. Get GPU info","metadata":{}},{"cell_type":"code","source":"# Make sure we're using a NVIDIA GPU\nif torch.cuda.is_available():\n  gpu_info = !nvidia-smi\n  gpu_info = '\\n'.join(gpu_info)\n  if gpu_info.find(\"failed\") >= 0:\n    print(\"Not connected to a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\")\n\n  # Get GPU name\n  gpu_name = !nvidia-smi --query-gpu=gpu_name --format=csv\n  gpu_name = gpu_name[1]\n  GPU_NAME = gpu_name.replace(\" \", \"_\") # remove underscores for easier saving\n  print(f'GPU name: {GPU_NAME}')\n\n  # Get GPU capability score\n  GPU_SCORE = torch.cuda.get_device_capability()\n  print(f\"GPU capability score: {GPU_SCORE}\")\n  if GPU_SCORE >= (8, 0):\n    print(f\"GPU score higher than or equal to (8, 0), PyTorch 2.x speedup features available.\")\n  else:\n    print(f\"GPU score lower than (8, 0), PyTorch 2.x speedup features will be limited (PyTorch 2.x speedups happen most on newer GPUs).\")\n  \n  # Print GPU info\n  print(f\"GPU information:\\n{gpu_info}\")\n\nelse:\n  print(\"PyTorch couldn't find a GPU, to leverage the best of PyTorch 2.0, you should connect to a GPU.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:12:27.749421Z","iopub.execute_input":"2024-06-12T10:12:27.749939Z","iopub.status.idle":"2024-06-12T10:12:27.980620Z","shell.execute_reply.started":"2024-06-12T10:12:27.749891Z","shell.execute_reply":"2024-06-12T10:12:27.979610Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"GPU name: Tesla_T4\nGPU capability score: (7, 5)\nGPU score lower than (8, 0), PyTorch 2.x speedup features will be limited (PyTorch 2.x speedups happen most on newer GPUs).\nGPU information:\nWed Jun 12 10:12:27 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n| N/A   33C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n| N/A   42C    P8              10W /  70W |      3MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 1.1 Globally set device","metadata":{}},{"cell_type":"code","source":"import torch \n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n\n# Set the device with context manager(PyTorch 2.x+)\nwith torch.device(device):\n    layer = torch.nn.Linear(20, 30)\n    print(f\"layer weights are on device: {layer.weight.device}\")\n    print(f\"layer creating data on device: {layer(torch.randn(128, 20)).device}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:19:59.221698Z","iopub.execute_input":"2024-06-12T10:19:59.222055Z","iopub.status.idle":"2024-06-12T10:19:59.229172Z","shell.execute_reply.started":"2024-06-12T10:19:59.222026Z","shell.execute_reply":"2024-06-12T10:19:59.228169Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"layer weights are on device: cuda:0\nlayer creating data on device: cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch \n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Set the device globally (Pytorch 2.x+)\ntorch.set_default_device(device)\n\nlayer = torch.nn.Linear(20, 30)\nprint(f\"layer weights are on device: {layer.weight.device}\")\nprint(f\"layer creating data on device: {layer(torch.randn(128, 20)).device}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:21:42.075637Z","iopub.execute_input":"2024-06-12T10:21:42.076222Z","iopub.status.idle":"2024-06-12T10:21:42.083488Z","shell.execute_reply.started":"2024-06-12T10:21:42.076191Z","shell.execute_reply":"2024-06-12T10:21:42.082526Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"layer weights are on device: cuda:0\nlayer creating data on device: cuda:0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2. Setting up the experiments","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"TorchVision version: {torchvision.__version__}\")\n\n# Set the target device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:32:01.712507Z","iopub.execute_input":"2024-06-12T10:32:01.712883Z","iopub.status.idle":"2024-06-12T10:32:01.718622Z","shell.execute_reply.started":"2024-06-12T10:32:01.712852Z","shell.execute_reply":"2024-06-12T10:32:01.717741Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"PyTorch version: 2.1.2\nTorchVision version: 0.16.2\nUsing device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.set_default_device(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:34:00.875960Z","iopub.execute_input":"2024-06-12T10:34:00.876541Z","iopub.status.idle":"2024-06-12T10:34:00.881047Z","shell.execute_reply.started":"2024-06-12T10:34:00.876508Z","shell.execute_reply":"2024-06-12T10:34:00.879958Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### 2.1 Create model and transforms","metadata":{}},{"cell_type":"code","source":"\ndef create_resnet50(num_classes:int=10):\n    weights = torchvision.models.ResNet50_Weights.DEFAULT\n    transforms = weights.transforms\n    model = torchvision.models.resnet50(weights=weights)\n    model.fc = torch.nn.Linear(in_features=2048,\n                         out_features=num_classes)\n\n    \n    return model, transforms\n    \nmodel, transforms = create_resnet50()\ntransforms","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:46:13.419088Z","iopub.execute_input":"2024-06-12T10:46:13.419439Z","iopub.status.idle":"2024-06-12T10:46:13.585043Z","shell.execute_reply.started":"2024-06-12T10:46:13.419410Z","shell.execute_reply":"2024-06-12T10:46:13.584135Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"functools.partial(<class 'torchvision.transforms._presets.ImageClassification'>, crop_size=224, resize_size=232)"},"metadata":{}}]},{"cell_type":"code","source":"total_params = sum(\nparam.numel() for param in model.parameters()\n)\ntotal_params","metadata":{"execution":{"iopub.status.busy":"2024-06-12T10:40:01.349523Z","iopub.execute_input":"2024-06-12T10:40:01.349942Z","iopub.status.idle":"2024-06-12T10:40:01.357430Z","shell.execute_reply.started":"2024-06-12T10:40:01.349913Z","shell.execute_reply":"2024-06-12T10:40:01.356560Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"25557032"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}