{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "73WfJtRRY_9D"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splits, info = tfds.load(\"horses_or_humans\",\n",
        "                         as_supervised=True, with_info=True, split=['train[:80%]', 'train[80%:]', 'test'],\n",
        "                         data_dir=\"./data\")\n",
        "\n",
        "train_examples, validation_examples, test_examples = splits\n",
        "\n",
        "num_examples = info.splits['train'].num_examples\n",
        "num_classes = info.features['label'].num_classes\n",
        "num_examples, num_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkHBZcZVZiRE",
        "outputId": "183c528f-4c61-4fcf-8818-f7b016118eb7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1027, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 224"
      ],
      "metadata": {
        "id": "rvskKWtOaN1P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a autograph pre-processing function to resize and normalize an image\n",
        "### START CODE HERE ###\n",
        "@tf.function\n",
        "def map_fn(image, label):\n",
        "  img = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "  img /= 255.\n",
        "  return img, label"
      ],
      "metadata": {
        "id": "sMVgj7iwajcl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TEST CODE:\n",
        "\n",
        "test_image, test_label = list(train_examples)[0]\n",
        "\n",
        "test_result = map_fn(test_image, test_label)\n",
        "\n",
        "print(test_result[0].shape)\n",
        "print(test_result[1].shape)\n",
        "\n",
        "del test_image, test_label, test_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvcElSIvcC_f",
        "outputId": "ed4d6696-dfd0-43db-a9ad-b222ea443d63"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(224, 224, 3)\n",
            "()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_examples.map(map_fn).shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
        "valid_ds = validation_examples.map(map_fn).batch(BATCH_SIZE)\n",
        "test_ds = test_examples.map(map_fn).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "YHXUrUHAcIuf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FRmDuCw-c17u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}