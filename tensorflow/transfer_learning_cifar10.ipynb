{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WV5KV0onO-AC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "8qZFoFPNQKgC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_img, y_train), (val_img, y_val) = tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIqaWI2UQOr6",
        "outputId": "b6b7ec1b-1176-4cee-f066-36304a5d19f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_images(input_images):\n",
        "  input_images = input_images.astype(\"float32\")\n",
        "  output_images = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_images"
      ],
      "metadata": {
        "id": "H3mxL1xMQcvV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = preprocess_images(train_img)\n",
        "X_val = preprocess_images(val_img)\n",
        "train = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size=1024).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "EDk8ZRkKQuum"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor_layer = tf.keras.applications.resnet.ResNet50(input_shape = (224, 224, 3),\n",
        "                                                                include_top = False,\n",
        "                                                                weights=\"imagenet\")\n",
        "inputs = tf.keras.layers.Input(shape=(32, 32, 3))\n",
        "resize = tf.keras.layers.UpSampling2D(size=(7, 7))(inputs)\n",
        "x = feature_extractor_layer(resize)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "# x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "# x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "Lh6dHdQqRTuu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for layer in feature_extractor_layer.layers:\n",
        "  layer.trainable = False\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge5HcGP2S1dx",
        "outputId": "8203528d-1ccc-49d8-f8a2-1a8e90de7fd7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " up_sampling2d_2 (UpSamplin  (None, 224, 224, 3)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d_2  (None, 2048)              0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23608202 (90.06 MB)\n",
            "Trainable params: 20490 (80.04 KB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "iyCJBQSgS8mn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train,\n",
        "          epochs=4,\n",
        "          validation_data=val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX4395XkTKHg",
        "outputId": "a6c6fae5-e1cf-4049-c471-baab5228d2d2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "1563/1563 [==============================] - 179s 113ms/step - loss: 0.7015 - accuracy: 0.7575 - val_loss: 0.5570 - val_accuracy: 0.8041\n",
            "Epoch 2/4\n",
            "1563/1563 [==============================] - 173s 111ms/step - loss: 0.5186 - accuracy: 0.8208 - val_loss: 0.5789 - val_accuracy: 0.8019\n",
            "Epoch 3/4\n",
            "1563/1563 [==============================] - 173s 111ms/step - loss: 0.4726 - accuracy: 0.8349 - val_loss: 0.5661 - val_accuracy: 0.8083\n",
            "Epoch 4/4\n",
            "1563/1563 [==============================] - 173s 111ms/step - loss: 0.4420 - accuracy: 0.8455 - val_loss: 0.5015 - val_accuracy: 0.8291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fbc94a591b0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jXpIvTgETgMf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}