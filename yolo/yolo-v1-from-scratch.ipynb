{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1556326,"sourceType":"datasetVersion","datasetId":918769}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\n","metadata":{"id":"rrQjcmVr7_k5","execution":{"iopub.status.busy":"2024-07-09T18:35:47.454397Z","iopub.execute_input":"2024-07-09T18:35:47.454862Z","iopub.status.idle":"2024-07-09T18:35:50.766721Z","shell.execute_reply.started":"2024-07-09T18:35:47.454827Z","shell.execute_reply":"2024-07-09T18:35:50.764998Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Yolo model","metadata":{"id":"JxfRAAy7Dt5o"}},{"cell_type":"code","source":"architecture_config = [\n    (7, 64, 2, 3),\n    \"M\",\n    (3, 192, 1, 1),\n    \"M\",\n    (1, 128, 1, 0),\n    (3, 256, 1, 1),\n    (1, 256, 1, 0),\n    (3, 512, 1, 1),\n    \"M\",\n    [(1, 256, 1, 0), (3, 512, 1, 1), 4],\n    (1, 512, 1, 0),\n    (3, 1024, 1, 1),\n    \"M\",\n    [(1, 512, 1, 0), (3, 1024, 1, 1), 2],\n    (3, 1024, 1, 1),\n    (3, 1024, 2, 1),\n    (3, 1024, 1, 1),\n    (3, 1024, 1, 1)\n]","metadata":{"id":"tSNfwaAF8L6V","execution":{"iopub.status.busy":"2024-07-09T18:35:51.748120Z","iopub.execute_input":"2024-07-09T18:35:51.748695Z","iopub.status.idle":"2024-07-09T18:35:51.759348Z","shell.execute_reply.started":"2024-07-09T18:35:51.748656Z","shell.execute_reply":"2024-07-09T18:35:51.758035Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class CNNBlock(nn.Module):\n  def __init__(self,\n               in_channels,\n               out_channels,\n               **kwargs):\n    super().__init__()\n    self.conv = nn.Conv2d(in_channels=in_channels,\n                          out_channels=out_channels,\n                          bias=False,\n                          **kwargs)\n    self.batch_norm = nn.BatchNorm2d(num_features=out_channels)\n    self.leaky_relu = nn.LeakyReLU(0.1)\n\n  def forward(self, x):\n    return self.leaky_relu(self.batch_norm(self.conv(x)))\n","metadata":{"id":"prIHSn6O9NUw","execution":{"iopub.status.busy":"2024-07-09T18:35:53.013453Z","iopub.execute_input":"2024-07-09T18:35:53.013883Z","iopub.status.idle":"2024-07-09T18:35:53.022194Z","shell.execute_reply.started":"2024-07-09T18:35:53.013852Z","shell.execute_reply":"2024-07-09T18:35:53.020884Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class YoloV1(nn.Module):\n  def __init__(self,\n               in_channels=3,\n               **kwargs):\n    super().__init__()\n    self.architecture = architecture_config\n    self.in_channels = in_channels\n    self.darknet = self._create_conv_layers(self.architecture)\n    self.fcs = self._create_fcs(**kwargs)\n\n  def forward(self, x):\n    x = self.darknet(x)\n    return self.fcs(torch.flatten(x, start_dim=1))\n\n  def _create_conv_layers(self, architecture):\n    layers = []\n    in_channels = self.in_channels\n\n    for x in architecture:\n      if type(x) == tuple:\n        layers += [CNNBlock(in_channels=in_channels,\n                           out_channels=x[1],\n                           kernel_size=x[0],\n                           stride=x[2],\n                           padding=x[3])]\n        in_channels = x[1]\n\n      elif type(x) == str:\n        layers += [nn.MaxPool2d(kernel_size=2,\n                               stride=2)]\n      elif type(x) == list:\n        conv1 = x[0]\n        conv2 = x[1]\n        num_repeats = x[2]\n\n        for _ in range(num_repeats):\n          layers += [CNNBlock(in_channels=in_channels,\n                             out_channels=conv1[1],\n                             kernel_size=conv1[0],\n                             stride=conv1[2],\n                             padding=conv1[3])]\n\n          in_channels = conv1[1]\n          layers += [CNNBlock(in_channels=in_channels,\n                             out_channels=conv2[1],\n                             kernel_size=conv2[0],\n                             stride=conv2[2],\n                             padding=conv2[3])]\n          in_channels = conv2[1]\n\n    return nn.Sequential(*layers)\n\n  def _create_fcs(self, split_size, num_boxes, num_classes):\n    S, B, C = split_size, num_boxes, num_classes\n    return nn.Sequential(\n        nn.Flatten(),\n        nn.Linear(1024*S*S, 496),\n        nn.Dropout(0.0),\n        nn.LeakyReLU(0.1),\n        nn.Linear(496, S*S*(C+B*5)),\n    )","metadata":{"id":"jTK61RzU-k0R","execution":{"iopub.status.busy":"2024-07-09T18:35:53.527576Z","iopub.execute_input":"2024-07-09T18:35:53.528011Z","iopub.status.idle":"2024-07-09T18:35:53.548105Z","shell.execute_reply.started":"2024-07-09T18:35:53.527974Z","shell.execute_reply":"2024-07-09T18:35:53.546791Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"test = torch.randn(size=(2,3, 448, 448))\nmodel = YoloV1(split_size=7, num_boxes=2, num_classes=20)\nmodel(test).shape","metadata":{"id":"GPEWvDnuH6aN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"823bcfa4-4238-4b9a-d5f6-cab3882aee6f","execution":{"iopub.status.busy":"2024-07-09T18:35:54.206034Z","iopub.execute_input":"2024-07-09T18:35:54.206546Z","iopub.status.idle":"2024-07-09T18:35:56.772337Z","shell.execute_reply.started":"2024-07-09T18:35:54.206506Z","shell.execute_reply":"2024-07-09T18:35:56.770441Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"torch.Size([2, 1470])"},"metadata":{}}]},{"cell_type":"markdown","source":"## Loss function","metadata":{"id":"EZnuWwYJIRB0"}},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/aladdinpersson/Machine-Learning-Collection/master/ML/Pytorch/object_detection/YOLO/utils.py","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RlbT8TiBGr_t","outputId":"41e84e11-b566-40db-933c-61d7a31775b2","execution":{"iopub.status.busy":"2024-07-09T18:35:56.775776Z","iopub.execute_input":"2024-07-09T18:35:56.776215Z","iopub.status.idle":"2024-07-09T18:35:58.253686Z","shell.execute_reply.started":"2024-07-09T18:35:56.776177Z","shell.execute_reply":"2024-07-09T18:35:58.251997Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"--2024-07-09 18:35:57--  https://raw.githubusercontent.com/aladdinpersson/Machine-Learning-Collection/master/ML/Pytorch/object_detection/YOLO/utils.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 11922 (12K) [text/plain]\nSaving to: 'utils.py'\n\nutils.py            100%[===================>]  11.64K  --.-KB/s    in 0s      \n\n2024-07-09 18:35:58 (57.2 MB/s) - 'utils.py' saved [11922/11922]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom utils import intersection_over_union","metadata":{"id":"4tTKqvVoIRwh","execution":{"iopub.status.busy":"2024-07-09T18:35:58.255715Z","iopub.execute_input":"2024-07-09T18:35:58.256131Z","iopub.status.idle":"2024-07-09T18:35:58.268449Z","shell.execute_reply.started":"2024-07-09T18:35:58.256083Z","shell.execute_reply":"2024-07-09T18:35:58.267243Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class YoloLoss(nn.Module):\n  def __init__(self, S=7, B=2, C=20):\n    super().__init__()\n    self.mse = nn.MSELoss(reduction=\"sum\")\n    self.S = S\n    self.B = B\n    self.C = C\n    self.lambda_noobj = 0.5\n    self.lambda_coord = 5\n\n  def forward(self, predictions, target):\n    predictions = predictions.reshape(-1, self.S, self.S, self.C + self.B*5)\n\n    iou_b1 = intersection_over_union(predictions[..., 21:25], target[..., 21:25])\n    iou_b2 = intersection_over_union(predictions[..., 26:30], target[..., 21:25])\n    ious = torch.cat([iou_b1.unsqueeze(0), iou_b2.unsqueeze(0)], dim=0)\n    iou_maxes, best_box = torch.max(ious, dim=0)\n    exists_box = target[..., 20].unsqueeze(3)\n\n    ## FOR BOX COORDINATES\n\n    box_predictions = exists_box * (best_box * predictions[..., 26:30] + (1 - best_box) * predictions[..., 21:25])\n    box_predictions[..., 2:4] = torch.sign(box_predictions * torch.sqrt(torch.abs(box_predictions[..., 2:4] + 1e-6)))\n\n    box_targets = exists_box * target[..., 21:25]\n    box_targets[..., 2:4] = torch.sqrt(box_targets[..., 2:4])\n\n    box_loss = self.mse(torch.flatten(box_predictions, end_dim=-2), torch.flatten(box_targets, end_dim=-2))\n\n    ## FOR OBJECT LOSS\n    pred_box = (best_box * predictions[..., 25:26] + (1 - best_box) * predictions[..., 20:21])\n    object_loss = self.mse(torch.flatten(exists_box * pred_box), torch.flatten(exists_box * target[..., 20:21]))\n\n    ## FOR NO OBJECT LOSS\n    no_object_loss = self.mse(torch.flatten((1 - exists_box) * predictions[..., 20:21], start_dim=1),\n                              torch.flatten((1 - exists_box) * target[..., 20:21], start_dim=1))\n\n    no_object_loss = self.mse(torch.flatten((1 - exists_box) * predictions[..., 25:26], start_dim=1),\n                              torch.flatten((1 - exists_box) * target[..., 20:21], start_dim=1))\n\n    ## FOR CLASS LOSS\n    class_loss = self.mse(torch.flatten(exists_box * predictions[..., :20], end_dim=-2),\n                          torch.flatten(exists_box * target[..., :20], end_dim=-2))\n\n    loss = self.lambda_coord * box_loss + object_loss + self.lambda_noobj * no_object_loss + class_loss\n\n    return loss","metadata":{"id":"copPq49WGuJV","execution":{"iopub.status.busy":"2024-07-09T18:35:58.271213Z","iopub.execute_input":"2024-07-09T18:35:58.271660Z","iopub.status.idle":"2024-07-09T18:35:58.292976Z","shell.execute_reply.started":"2024-07-09T18:35:58.271618Z","shell.execute_reply":"2024-07-09T18:35:58.291547Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Loading the dataset","metadata":{}},{"cell_type":"code","source":"%%writefile dataset.py\n\nimport torch\nimport os\nimport pandas as pd\nfrom PIL import Image\n\nclass VOCDataset(torch.utils.data.Dataset):\n    def __init__(self,\n                 csv_file,\n                 img_dir, \n                 label_dir,\n                 S=7,\n                 B=2,\n                 C=20, \n                 transform=None):\n        self.annotations = pd.read_csv(csv_file)\n        self.img_dir = img_dir\n        self.label_dir = lable_dir\n        self.transform = transform\n        self.S = S\n        self.B = B\n        self.C = C\n        \n    def __len__(self):\n        return len(self.annotations)\n    \n    def __getitem__(self, index):\n        label_path = os.path.join(self.label_dir, self.annotations.iloc[index, 1])\n        boxes = []\n        with open(label_path) as f:\n            for label in f.readlines():\n                class_label, x, y, width, height = [float(x) if float(x) != int(float(x)) else int(x) \n                                                    for x in label.replace(\"\\n\", \"\").split()]\n                \n                boxes.append([class_label, x, y, width, height])\n                \n        img_path = os.path.join(self.img_dir, self.annotations.iloc(index, 0))\n        image = Image.open(img_path)\n        boxes = torch.tensor(boxes)\n        if self.transform:\n            image, boxes = self.transform(image, boxes)\n        \n        label_matrix = torch.zeros((self.S, self.S, self.C+5*self.B))\n        for box in boxes:\n            class_label, x, y, width, height = box.tolist()\n            class_label = int(class_label)\n            i, j = int(self.S*y), int(self.S*x)\n            X_cell, y_cell = self.S * x - j, self.X * y - i\n            width_cell, height_cell = width * self.S, heigth * self.S\n            \n            if label_matrix[i, j, 20] == 0:\n                label_matrix[i, j, 20] = 1\n                box_coordinates = torch.tensor([x_cell, y_cell, width_cell, height_cell])\n                label_matrix[i, j, 21:25] = box_coordinates\n                label_matrix[i, j, class_label] = 1\n                \n        return image, label_matrix","metadata":{"execution":{"iopub.status.busy":"2024-07-09T19:02:08.717747Z","iopub.execute_input":"2024-07-09T19:02:08.718171Z","iopub.status.idle":"2024-07-09T19:02:08.728451Z","shell.execute_reply.started":"2024-07-09T19:02:08.718137Z","shell.execute_reply":"2024-07-09T19:02:08.727112Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Writing dataset.py\n","output_type":"stream"}]},{"cell_type":"code","source":"annotations = pd.read_csv(\"/kaggle/input/pascalvoc-yolo/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-07-09T18:41:15.943813Z","iopub.execute_input":"2024-07-09T18:41:15.944261Z","iopub.status.idle":"2024-07-09T18:41:16.010901Z","shell.execute_reply.started":"2024-07-09T18:41:15.944224Z","shell.execute_reply":"2024-07-09T18:41:16.009216Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"annotations.iloc[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-09T18:41:59.934156Z","iopub.execute_input":"2024-07-09T18:41:59.934620Z","iopub.status.idle":"2024-07-09T18:41:59.945652Z","shell.execute_reply.started":"2024-07-09T18:41:59.934582Z","shell.execute_reply":"2024-07-09T18:41:59.944328Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"000005.jpg    000007.jpg\n000005.txt    000007.txt\nName: 0, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}