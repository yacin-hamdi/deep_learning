{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rrQjcmVr7_k5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Yolo model"
      ],
      "metadata": {
        "id": "JxfRAAy7Dt5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "architecture_config = [\n",
        "    (7, 64, 2, 3),\n",
        "    \"M\",\n",
        "    (3, 192, 1, 1),\n",
        "    \"M\",\n",
        "    (1, 128, 1, 0),\n",
        "    (3, 256, 1, 1),\n",
        "    (1, 256, 1, 0),\n",
        "    (3, 512, 1, 1),\n",
        "    \"M\",\n",
        "    [(1, 256, 1, 0), (3, 512, 1, 1), 4],\n",
        "    (1, 512, 1, 0),\n",
        "    (3, 1024, 1, 1),\n",
        "    \"M\",\n",
        "    [(1, 512, 1, 0), (3, 1024, 1, 1), 2],\n",
        "    (3, 1024, 1, 1),\n",
        "    (3, 1024, 2, 1),\n",
        "    (3, 1024, 1, 1),\n",
        "    (3, 1024, 1, 1)\n",
        "]"
      ],
      "metadata": {
        "id": "tSNfwaAF8L6V"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNBlock(nn.Module):\n",
        "  def __init__(self,\n",
        "               in_channels,\n",
        "               out_channels,\n",
        "               **kwargs):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(in_channels=in_channels,\n",
        "                          out_channels=out_channels,\n",
        "                          bias=False,\n",
        "                          **kwargs)\n",
        "    self.batch_norm = nn.BatchNorm2d(num_features=out_channels)\n",
        "    self.leaky_relu = nn.LeakyReLU(0.1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.leaky_relu(self.batch_norm(self.conv(x)))\n"
      ],
      "metadata": {
        "id": "prIHSn6O9NUw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YoloV1(nn.Module):\n",
        "  def __init__(self,\n",
        "               in_channels=3,\n",
        "               **kwargs):\n",
        "    super().__init__()\n",
        "    self.architecture = architecture_config\n",
        "    self.in_channels = in_channels\n",
        "    self.darknet = self._create_conv_layers(self.architecture)\n",
        "    self.fcs = self._create_fcs(**kwargs)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.darknet(x)\n",
        "    return self.fcs(torch.flatten(x, start_dim=1))\n",
        "\n",
        "  def _create_conv_layers(self, architecture):\n",
        "    layers = []\n",
        "    in_channels = self.in_channels\n",
        "\n",
        "    for x in architecture:\n",
        "      if type(x) == tuple:\n",
        "        layers += [CNNBlock(in_channels=in_channels,\n",
        "                           out_channels=x[1],\n",
        "                           kernel_size=x[0],\n",
        "                           stride=x[2],\n",
        "                           padding=x[3])]\n",
        "        in_channels = x[1]\n",
        "\n",
        "      elif type(x) == str:\n",
        "        layers += [nn.MaxPool2d(kernel_size=2,\n",
        "                               stride=2)]\n",
        "      elif type(x) == list:\n",
        "        conv1 = x[0]\n",
        "        conv2 = x[1]\n",
        "        num_repeats = x[2]\n",
        "\n",
        "        for _ in range(num_repeats):\n",
        "          layers += [CNNBlock(in_channels=in_channels,\n",
        "                             out_channels=conv1[1],\n",
        "                             kernel_size=conv1[0],\n",
        "                             stride=conv1[2],\n",
        "                             padding=conv1[3])]\n",
        "\n",
        "          in_channels = conv1[1]\n",
        "          layers += [CNNBlock(in_channels=in_channels,\n",
        "                             out_channels=conv2[1],\n",
        "                             kernel_size=conv2[0],\n",
        "                             stride=conv2[2],\n",
        "                             padding=conv2[3])]\n",
        "          in_channels = conv2[1]\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def _create_fcs(self, split_size, num_boxes, num_classes):\n",
        "    S, B, C = split_size, num_boxes, num_classes\n",
        "    return nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(1024*S*S, 496),\n",
        "        nn.Dropout(0.0),\n",
        "        nn.LeakyReLU(0.1),\n",
        "        nn.Linear(496, S*S*(C+B*5)),\n",
        "    )"
      ],
      "metadata": {
        "id": "jTK61RzU-k0R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = torch.randn(size=(2,3, 448, 448))\n",
        "model = YoloV1(split_size=7, num_boxes=2, num_classes=20)\n",
        "model(test).shape"
      ],
      "metadata": {
        "id": "GPEWvDnuH6aN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823bcfa4-4238-4b9a-d5f6-cab3882aee6f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1470])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss function"
      ],
      "metadata": {
        "id": "EZnuWwYJIRB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/aladdinpersson/Machine-Learning-Collection/master/ML/Pytorch/object_detection/YOLO/utils.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlbT8TiBGr_t",
        "outputId": "41e84e11-b566-40db-933c-61d7a31775b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-08 11:29:12--  https://raw.githubusercontent.com/aladdinpersson/Machine-Learning-Collection/master/ML/Pytorch/object_detection/YOLO/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11922 (12K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "\rutils.py              0%[                    ]       0  --.-KB/s               \rutils.py            100%[===================>]  11.64K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-07-08 11:29:12 (30.4 MB/s) - ‘utils.py’ saved [11922/11922]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from utils import intersection_over_union"
      ],
      "metadata": {
        "id": "4tTKqvVoIRwh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YoloLoss(nn.Module):\n",
        "  def __init__(self, S=7, B=2, C=20):\n",
        "    super().__init__()\n",
        "    self.mse = nn.MSELoss(reduction=\"sum\")\n",
        "    self.S = S\n",
        "    self.B = B\n",
        "    self.C = C\n",
        "    self.lambda_noobj = 0.5\n",
        "    self.lambda_coord = 5\n",
        "\n",
        "  def forward(self, predictions, target):\n",
        "    predictions = predictions.reshape(-1, self.S, self.S, self.C + self.B*5)\n",
        "\n",
        "    iou_b1 = intersection_over_union(predictions[..., 21:25], target[..., 21:25])\n",
        "    iou_b2 = intersection_over_union(predictions[..., 26:30], target[..., 21:25])\n",
        "    ious = torch.cat([iou_b1.unsqueeze(0), iou_b2.unsqueeze(0)], dim=0)\n",
        "    iou_maxes, best_box = torch.max(ious, dim=0)\n",
        "    exists_box = target[..., 20].unsqueeze(3)\n",
        "\n",
        "    ## FOR BOX COORDINATES\n",
        "\n",
        "    box_predictions = exists_box * (best_box * predictions[..., 26:30] + (1 - best_box) * predictions[..., 21:25])\n",
        "    box_predictions[..., 2:4] = torch.sign(box_predictions * torch.sqrt(torch.abs(box_predictions[..., 2:4] + 1e-6)))\n",
        "\n",
        "    box_targets = exists_box * target[..., 21:25]\n",
        "    box_targets[..., 2:4] = torch.sqrt(box_targets[..., 2:4])\n",
        "\n",
        "    box_loss = self.mse(torch.flatten(box_predictions, end_dim=-2), torch.flatten(box_targets, end_dim=-2))\n",
        "\n",
        "    ## FOR OBJECT LOSS\n",
        "    pred_box = (best_box * predictions[..., 25:26] + (1 - best_box) * predictions[..., 20:21])\n",
        "    object_loss = self.mse(torch.flatten(exists_box * pred_box), torch.flatten(exists_box * target[..., 20:21]))\n",
        "\n",
        "    ## FOR NO OBJECT LOSS\n",
        "    no_object_loss = self.mse(torch.flatten((1 - exists_box) * predictions[..., 20:21], start_dim=1),\n",
        "                              torch.flatten((1 - exists_box) * target[..., 20:21], start_dim=1))\n",
        "\n",
        "    no_object_loss = self.mse(torch.flatten((1 - exists_box) * predictions[..., 25:26], start_dim=1),\n",
        "                              torch.flatten((1 - exists_box) * target[..., 20:21], start_dim=1))\n",
        "\n",
        "    ## FOR CLASS LOSS\n",
        "    class_loss = self.mse(torch.flatten(exists_box * predictions[..., :20], end_dim=-2),\n",
        "                          torch.flatten(exists_box * target[..., :20], end_dim=-2))\n",
        "\n",
        "    loss = self.lambda_coord * box_loss + object_loss + self.lambda_noobj * no_object_loss + class_loss\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "copPq49WGuJV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XkU-P6iqNaCE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}